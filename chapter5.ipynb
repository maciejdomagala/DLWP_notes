{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x260763db898>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#magic function, plots will be visible in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#statement of the problem:\n",
    "#we want to find the correlation between temperatures t_c and t_u. To be exact, we want to find the \n",
    "#transformation (possibly linear) that is needed to convert temp. units (t_u) to t_c.\n",
    "\n",
    "# temperature data\n",
    "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0]\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
    "t_c = torch.tensor(t_c)\n",
    "t_u = torch.tensor(t_u)\n",
    "\n",
    "plt.scatter(t_c, t_u)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "torch.FloatTensor\n",
      "tensor(1.)\n",
      "torch.Size([])\n",
      "torch.Size([])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1763.8846)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proceeding with the linear type of model (essentially defining linear regression from scratch)\n",
    "\n",
    "#approach: we want to create a linear function that converts t_u to values t_p. t_p are meant\n",
    "#to be the values as close to t_c as possible. w - weights, b - bias (y = w*x + b).\n",
    "\n",
    "def model(t_u, w, b):\n",
    "    return w * t_u + b\n",
    "\n",
    "# we are applying the L2 kind of loss (MSE). More robust for outliers, penalizes very wrong results more that L1 metric.\n",
    "\n",
    "def loss(t_p, t_c):\n",
    "    loss = (t_p - t_c)**2\n",
    "    return loss.mean()\n",
    "\n",
    "#test\n",
    "# test_c = torch.tensor([2], dtype = float)\n",
    "# test_p = torch.tensor([1], dtype = float)\n",
    "\n",
    "# print(loss(test_c, test_p))\n",
    "\n",
    "# w and b initializing\n",
    "w = torch.ones(())\n",
    "b = torch.zeros(())\n",
    "\n",
    "print(w.shape)\n",
    "print(w.type())\n",
    "print(w)\n",
    "print(w.size())\n",
    "\n",
    "# calculating t_p for earlier defined t_u\n",
    "\n",
    "t_p = model(t_u, w, b)\n",
    "loss(t_p, t_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[1., 1.],\n",
      "           [1., 1.],\n",
      "           [1., 1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[1., 1.],\n",
      "           [1., 1.],\n",
      "           [1., 1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[1., 1.],\n",
      "           [1., 1.],\n",
      "           [1., 1.]]]]])\n",
      "torch.Size([3, 1, 1, 3, 2])\n",
      "Shapes of the tensors: x - torch.Size([]), y - torch.Size([3, 1, 1, 1, 1]))\n",
      "Shapes of the tensors: z - torch.Size([1, 3]), a - torch.Size([2, 1, 1]))\n",
      "tensor([[[[[1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[1.]]]]])\n",
      "tensor([[[1.]],\n",
      "\n",
      "        [[1.]]])\n",
      "tensor([[[[[1.]],\n",
      "\n",
      "          [[1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[1.]],\n",
      "\n",
      "          [[1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[1.]],\n",
      "\n",
      "          [[1.]]]]])\n",
      "Shapes of the tensors: y*a - torch.Size([3, 1, 2, 1, 1])\n",
      "Shapes of the tensors: a*z - torch.Size([2, 1, 3])\n",
      "Shapes of the tensors: y*a*z - torch.Size([3, 1, 2, 1, 3])\n",
      "tensor([[[[[1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1.]]]]])\n"
     ]
    }
   ],
   "source": [
    "# BROADCASTING\n",
    "# pytorch functionality that allow us to perform operations of tensors that are not necessarily of the same size/shape.\n",
    "\n",
    "x = torch.ones(())\n",
    "y = torch.ones(3,1,1,1,1)\n",
    "z = torch.ones(1,3)\n",
    "a = torch.ones(2,1,1)\n",
    "f = torch.ones(3,2)\n",
    "\n",
    "print(y*f)\n",
    "print((y*f).shape)\n",
    "\n",
    "print(f\"Shapes of the tensors: x - {x.shape}, y - {y.shape})\")\n",
    "print(f\"Shapes of the tensors: z - {z.shape}, a - {a.shape})\")\n",
    "\n",
    "print(y)\n",
    "print(a)\n",
    "print(y*a)\n",
    "\n",
    "print(f\"Shapes of the tensors: y*a - {(y*a).shape}\")\n",
    "print(f\"Shapes of the tensors: a*z - {(a*z).shape}\")\n",
    "print(f\"Shapes of the tensors: y*a*z - {(y*a*z).shape}\")\n",
    "print(y*a*z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35.7000, 55.9000, 58.2000, 81.9000, 56.3000, 48.9000, 33.9000, 21.8000,\n",
      "        48.4000, 60.4000, 68.4000])\n",
      "tensor(51.8000)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000])\n",
      "tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "# rate of change calculating\n",
    "\n",
    "delta = 0.1\n",
    "loss_rate_of_change_w = (model(t_u, w + delta, b) - model(t_u, w - delta, b))/(2*delta)\n",
    "print(loss_rate_of_change_w)\n",
    "print(loss_rate_of_change_w.mean())\n",
    "\n",
    "#same calculating for the b parameter\n",
    "loss_rate_of_change_b = (model(t_u, w, b + delta) - model(t_u, w, b - delta))/(2*delta)\n",
    "print(loss_rate_of_change_b)\n",
    "print(loss_rate_of_change_b.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#derivatives for the gradient descent\n",
    "\n",
    "#first, derivative of the loss function (which is a quadratic function, MSE)\n",
    "#remembering that t_p is the the variable here\n",
    "def dloss(t_p, t_c):\n",
    "    dloss = 2*(t_p - t_c)\n",
    "    return dloss / t_p.size() #division necessary to address the mean calculation from the model\n",
    "\n",
    "#second, derivative of the model function (linear)\n",
    "\n",
    "#two variables here, w and b, so two functions\n",
    "def dmodel_dw(t_u, w, b):\n",
    "    return t_u\n",
    "\n",
    "def dmodel_db(t_u, w, b):\n",
    "    return 1.0\n",
    "\n",
    "#calculating the whole gradient in the one function\n",
    "\n",
    "def grad(t_u, )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
